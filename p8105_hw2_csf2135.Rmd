---
title: "P8105_Homework 2"
author: "UNI: csf2135"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(readxl)
library(tidyverse)
```

### Problem 1: Carolyn's Way 

**Our goal is to merge these into a single data frame using year and month as keys across datasets.**

First, clean the data in `pols-month.csv`. 

  * Use `separate()` to break up the variable mon into integer variables year, month, and day; 
  * replace month number with month name; 
  * create a president variable taking values gop and dem, and remove prez_dem and prez_gop; 
  * and remove the day variable.
```{r clean_538_my_way, message=FALSE, echo=TRUE}
pols_month_df = read_csv("fivethirtyeight_datasets/pols-month.csv")

pols_month_df = pols_month_df |> 
  separate(mon, into = c("year","month","day"), "-") |> 
  mutate(
    month= as.numeric(month)
    )|> 
  mutate(
    month_abb= case_match(
    month, 
    1 ~ "Jan", 
    2 ~ "Feb", 
    3 ~ "Mar", 
    4 ~ "Apr", 
    5 ~ "May", 
    6 ~ "Jun", 
    7 ~ "Jul", 
    8 ~ "Aug", 
    9 ~ "Sep", 
    10 ~ "Oct", 
    11 ~ "Nov", 
    12 ~ "Dec"
  ), 
  president= case_when(
    prez_gop == 1 ~ "gop", 
    prez_gop == 2 ~ "gop", 
    prez_dem == 1 ~ "dem"
  )) |> 
  select(-prez_gop, -prez_dem, -day) |> 
  relocate(year, month_abb)
```

Second, clean the data in `snp.csv` using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.
```{r clean_snp_my_way, message=FALSE, echo=TRUE}
snp_df = read_csv("fivethirtyeight_datasets/snp.csv")

snp_df = snp_df |> 
  separate(date, into = c("month", "day", "year"), "/") |> 
  mutate(
    month= as.numeric(month)
    )|> 
  mutate(
    month_abb= case_match(
    month, 
    1 ~ "Jan", 
    2 ~ "Feb", 
    3 ~ "Mar", 
    4 ~ "Apr", 
    5 ~ "May", 
    6 ~ "Jun", 
    7 ~ "Jul", 
    8 ~ "Aug", 
    9 ~ "Sep", 
    10 ~ "Oct", 
    11 ~ "Nov", 
    12 ~ "Dec"
  ), 
  year= case_when(
    year <16 ~ paste0("20",year), 
    year >=16 ~ paste0("19", year)
  )) |> 
  relocate(year, month_abb)
```

Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.
```{r clean_unempl_my_way, message=FALSE, echo=TRUE}
unemployment_df <- read_csv("fivethirtyeight_datasets/unemployment.csv", 
                            col_types = cols(Year = col_character()))

unemployment_df= unemployment_df |> 
  pivot_longer(
    Jan:Dec, 
    names_to ="month_abb", 
    values_to = "rate_unemployment"
  ) |> 
  relocate(year= Year, month_abb)

```

Join the datasets by merging `snp` into `pols`, and merging `unemployment` into the result.
```{r merge_538_my_way, message=FALSE, echo=TRUE}
joined_df= left_join(pols_month_df, snp_df, by=c("year", "month_abb")) |> 
  left_join(unemployment_df, by=c("year", "month_abb"))
```

Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

_The final data set `joined_df` contains information about the number of politicians per party, market performance, and unemployment rate per month for the years 1947-2015. The final data set contains `r ncol(joined_df)` variables and `r nrow(joined_df)` rows. This data set was created by joining `pols-month.csv` data which includes data for the number of governors per party (`gov_gop`, `gov_dem`), number of representatives per party (`rep_gov`, `rep_dem`), number of senators per party (`sen_gop`, `sen_dem`), and the party affiliation of the president (`president`) for the years 1947-2015. `pols.csv` has `r ncol(pols_month_df)` variables and `r nrow(pols_month_df)` rows. The `snp.csv` data was also joined, which includes S&P index (`close`) to track stock market performance per day from January 1950- July 2015. `snp.csv` has `r ncol(snp_df)` variables and `r nrow(snp_df)` rows. The third data set used to make the final data set was the `unemployment.csv` which contains monthly national unemployment rate (`rate_unemployment`) for 1948- 2015. `unemployment.csv` has `r ncol(unemployment_df)` variables and `r nrow(unemployment_df)` rows. The three datasets were joined by `month` and `year`to create the final dataset._



### Problem 1: Posted solution

We clean the 538 `pols` data, which provides information on the number of national politicians who are democratic or republican at any given time. There are some values for which `prez_gop` is `2` -- these are months in which Ford became President following Nixon's resignation. In the new `president` variable created as part of our data cleaning, we code these as `gop` (same as values when `prez_gop` is `1`).

```{r clean_538_key, message=FALSE, echo=TRUE}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

We also clean the 538 `snp` data, which contains information related to Standard & Poor’s stock market index.

```{r clean_snp_key, message=FALSE, echo=TRUE}
snp = 
  read_csv("fivethirtyeight_datasets/snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 
```

Finally, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.

```{r clean_unempl_key, message=FALSE, echo=TRUE}
unemployment = 
  read_csv("fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Now we merge the three datasets!

```{r merge_538_snp_key, message=FALSE, results='hide', echo=TRUE}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

Notice that there are some `NA` values in the `close` and `unemployment` variables, which indicate that the value of these variables is missing at those locations.

Let's talk about the 538 datasets. The `pols` data has `r nrow(pols)` observations and `r ncol(pols)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r range(pols$year)[1]` to `r range(pols$year)[2]`. It also tells us whether the sitting president was a democrat or republican. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, ranging from years `r range(snp$year)[1]` to `r range(snp$year)[2]`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables ranging from years `r range(unemployment$year)[1]` to `r range(unemployment$year)[2]`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.


## Problem 2
Read and clean the Mr. Trash Wheel sheet:

  * specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
  * use reasonable variable names
  * omit rows that do not include dumpster-specific data
  * Update the data to include a new homes_powered variable based on this calculation: 

_Homes Powered - Each ton of trash equates to on average 500 kilowatts of electricity.  An average household will use 30 kilowatts per day._


```{r, message=FALSE, echo=TRUE}
mr_trash_df= readxl::read_excel("202207 Trash Wheel Collection Data.xlsx", 
                                sheet = "Mr. Trash Wheel", 
                                range = "A2:N549") |> 
  janitor::clean_names() |> 
  mutate(
    year= as.numeric(year), 
    homes_powered = (weight_tons * 500)/30, 
    dumpster_name= "Mr. Trash Wheel"
    )
```

Use a similar process to import, clean, and organize the data for Professor Trash Wheel and Gwynnda, and combine these with the Mr. Trash Wheel dataset to produce a single tidy dataset. 

```{r, message=FALSE, echo=TRUE}
prof_trash_df <- readxl::read_excel("202207 Trash Wheel Collection Data.xlsx", 
                                  sheet = "Professor Trash Wheel", 
                                  range = "A2:M96") |> 
  janitor::clean_names() |> 
  mutate(
    homes_powered = (weight_tons * 500)/30, 
    dumpster_name = "Prof. Trash Wheel"
  )

gwynnda_df <- readxl::read_excel("202207 Trash Wheel Collection Data.xlsx", 
                                 sheet = "Gwynnda Trash Wheel", 
                                 range = "A2:K108") |> 
  janitor::clean_names() |> 
  mutate(
    homes_powered = (weight_tons * 500) / 30, 
    dumpster_name = "Gwynnda Trash Wheel"  
  )

all_trash= bind_rows(mr_trash_df, prof_trash_df, gwynnda_df) |> 
  relocate(dumpster_name, dumpster, month, year, date)
```


_Upon inspecting full `all_trash` dataset, it was observed that one data observation was miscoded. For Mr. Trash Wheel dumpster 383 (January 2020) the date shown in data is "1900-01-20"). Will replace the year of this date with 2020 and I should follow-up to cross check trash collection days for Mr. Trash Wheel to ensure the month and day have been entered correctly._
```{r, message=FALSE, echo=TRUE}

all_trash <- all_trash |> 
  mutate(date = if_else((dumpster == 383 & year == 2020),
                        paste0(as.Date("2020-01-20")), paste0(date))) 

```

Write a paragraph about these data. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. 

_The `all_trash` data set contains information about the types of trash collected, total weight of trash in tons collected (`weight_tons`), and an approximate value for number of homes powered by trash collection (`homes_powered`) for the trash wheels: `r unique(all_trash$dumpster_name)`. The dataset contains trash collection data for `r min(all_trash$date)` through `r max(all_trash$date)`. There are `r ncol(all_trash)` variables and `r nrow(all_trash)` observations._

_Note that plastic bag collection data are only reported for Gwynnda Trash Wheel. Glass bottle, grocery bag, and chip bag collection data are reported for Mr. Trash Wheel and Professor Trash Well. Sports ball collection data are reported for Mr. Trash only._

For available data, what was the total weight of trash collected by Professor Trash Wheel? 

_The total weight of trash collected by Professor Trash Wheel was `r sum(filter(all_trash, dumpster_name == "Prof. Trash Wheel")  |>  pull(weight_tons))` tons._


What was the total number of cigarette butts collected by Gwynnda in July of 2021?

_In July of 2021. Gwynnda collected In July of 2021, Gwynnda collected `r as.integer(sum(filter(all_trash, dumpster_name == "Gwynnda Trash Wheel" & month == "July" & year == 2021)  |>  pull(cigarette_butts)))` cigarette butts.


## Problem 3

This problem uses data collected in an observational study to understand the trajectory of Alzheimer’s disease (AD) biomarkers. Study participants were free of Mild Cognitive Impairment (MCI), a stage between the expected cognitive decline of normal aging and the more serious decline of dementia, at the study baseline.

Basic demographic information were measured at the study baseline. The study monitored the development of MCI and recorded the age of MCI onset during the follow-up period, with the last visit marking the end of follow-up. APOE4 is a variant of the apolipoprotein E gene, significantly associated with a higher risk of developing Alzheimer’s disease. The amyloid β 42/40 ratio holds significant promise for diagnosing and predicting disease outcomes. This ratio undergoes changes over time and has been linked to the manifestation of clinical symptoms of Alzheimer’s disease.

Import, clean, and tidy the dataset of baseline demographics. 

  * Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), 
  * and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline). 
```{r clean_baseline, message=FALSE}
baseline_df <- read_csv("data_mci/MCI_baseline.csv", skip = 1) |> 
  janitor::clean_names() |> 
  rename(study_id = id) |> 
  mutate(sex = case_when(
    sex == 1 ~ "Male", 
    sex == 0 ~ "Female"
  )) |>  
  mutate(apoe4 = case_when(
    apoe4 == 1 ~ "apoe4 carrier", 
    apoe4 == 0 ~ "apoe4 non-carrier"
  )) |> 
  filter(current_age != age_at_onset)
```

Discuss important steps in the import process and relevant features of the dataset. 

_The import and cleaning of the `baseline_df` dataset involves changing all names to snake case using `clean_names()`, renaming the study participant identifier and primary key to `study_id` for joining to the `amyloid_df` dataset, replacing numerical indicators for `sex` to interpretable character values where `1`= `male` and `0`= `female`, and replacing numerical indicators for `apoe4` status so that `1`= `apoe4 carrier` and `0`= `apoe4 non-carrier`. Finally, the dataset was filtered to exclude participants who demonstrated MCI at baseline. One participant (study_id: 234) was excluded._

_The imported baseline data included 483 observations, the cleaned baseline data has `r nrow(baseline_df)` observations._

How many participants were recruited, and of these how many develop MCI? 

_The study recruited 
`r length(unique(as.character(baseline_df |>  pull(study_id))))` 
eligible participants. Of these, 
`r length(unique(as.character(baseline_df |> filter(age_at_onset != ".") |> pull(study_id))))` 
participants developed MCI during the study observation period._

What is the average baseline age? What proportion of women in the study are APOE4 carriers?

_The average age of participants at baseline is 
`r round(mean(baseline_df |> pull (current_age)), digit=2)` 
years. 
The study included 
`r length(unique(as.character(baseline_df |> filter(sex == "Female") |> pull(study_id))))` 
females, of which 
`r round(length(baseline_df |> filter(sex == "Female" & apoe4 == "apoe4 carrier") |> pull(apoe4))/length(unique(as.character(baseline_df |> filter(sex == "Female") |> pull(study_id))))* 100, digit = 2)`%
were carriers for the APOE4 gene._


Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values; comment on the steps on the import process and the features of the dataset.
```{r}
amyloid_df <- read_csv("data_mci/mci_amyloid.csv", skip = 1) |> 
  janitor::clean_names() 
```


Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory.

return all rows from x without a match in y...
```{r}
test<- anti_join(baseline_df, amyloid_df, by=c("study_id"))

test2<- anti_join(amyloid_df, baseline_df, by=c("study_id"))

```







