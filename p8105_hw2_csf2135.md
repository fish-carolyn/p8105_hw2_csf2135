P8105_Homework 2
================
UNI: csf2135

### Problem 1: Carolyn’s Way

**Our goal is to merge these into a single data frame using year and
month as keys across datasets.**

First, clean the data in `pols-month.csv`.

- Use `separate()` to break up the variable mon into integer variables
  year, month, and day;
- replace month number with month name;
- create a president variable taking values gop and dem, and remove
  prez_dem and prez_gop;
- and remove the day variable.

``` r
pols_month_df = read_csv("fivethirtyeight_datasets/pols-month.csv")

pols_month_df = pols_month_df |> 
  separate(mon, into = c("year","month","day"), "-") |> 
  mutate(
    month= as.numeric(month)
    )|> 
  mutate(
    month_abb= case_match(
    month, 
    1 ~ "Jan", 
    2 ~ "Feb", 
    3 ~ "Mar", 
    4 ~ "Apr", 
    5 ~ "May", 
    6 ~ "Jun", 
    7 ~ "Jul", 
    8 ~ "Aug", 
    9 ~ "Sep", 
    10 ~ "Oct", 
    11 ~ "Nov", 
    12 ~ "Dec"
  ), 
  president= case_when(
    prez_gop == 1 ~ "gop", 
    prez_gop == 2 ~ "gop", 
    prez_dem == 1 ~ "dem"
  )) |> 
  select(-prez_gop, -prez_dem, -day) |> 
  relocate(year, month_abb)
```

Second, clean the data in `snp.csv` using a similar process to the
above. For consistency across datasets, arrange according to year and
month, and organize so that year and month are the leading columns.

``` r
snp_df = read_csv("fivethirtyeight_datasets/snp.csv")

snp_df = snp_df |> 
  separate(date, into = c("month", "day", "year"), "/") |> 
  mutate(
    month= as.numeric(month)
    )|> 
  mutate(
    month_abb= case_match(
    month, 
    1 ~ "Jan", 
    2 ~ "Feb", 
    3 ~ "Mar", 
    4 ~ "Apr", 
    5 ~ "May", 
    6 ~ "Jun", 
    7 ~ "Jul", 
    8 ~ "Aug", 
    9 ~ "Sep", 
    10 ~ "Oct", 
    11 ~ "Nov", 
    12 ~ "Dec"
  ), 
  year= case_when(
    year <16 ~ paste0("20",year), 
    year >=16 ~ paste0("19", year)
  )) |> 
  relocate(year, month_abb)
```

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemployment_df <- read_csv("fivethirtyeight_datasets/unemployment.csv", 
                            col_types = cols(Year = col_character()))

unemployment_df= unemployment_df |> 
  pivot_longer(
    Jan:Dec, 
    names_to ="month_abb", 
    values_to = "rate_unemployment"
  ) |> 
  relocate(year= Year, month_abb)
```

Join the datasets by merging `snp` into `pols`, and merging
`unemployment` into the result.

``` r
joined_df= left_join(pols_month_df, snp_df, by=c("year", "month_abb")) |> 
  left_join(unemployment_df, by=c("year", "month_abb"))
```

*Write a short paragraph about these datasets. Explain briefly what each
dataset contained, and describe the resulting dataset (e.g. give the
dimension, range of years, and names of key variables).*

*The final data set `joined_df` contains information about the number of
politicians per party, market performance, and unemployment rate per
month for the years 1947-2015. The final data set contains 14 variables
and 822 rows. This data set was created by joining `pols-month.csv` data
which includes data for the number of governors per party (`gov_gop`,
`gov_dem`), number of representatives per party (`rep_gov`, `rep_dem`),
number of senators per party (`sen_gop`, `sen_dem`), and the party
affiliation of the president (`president`) for the years 1947-2015.
`pols.csv` has 10 variables and 822 rows. The `snp.csv` data was also
joined, which includes S&P index (`close`) to track stock market
performance per day from January 1950- July 2015. `snp.csv` has 5
variables and 787 rows. The third data set used to make the final data
set was the `unemployment.csv` which contains monthly national
unemployment rate (`rate_unemployment`) for 1948- 2015.
`unemployment.csv` has 3 variables and 816 rows. The three datasets were
joined by `month` and `year`to create the final dataset.*

### Problem 1: Posted solution

We clean the 538 `pols` data, which provides information on the number
of national politicians who are democratic or republican at any given
time. There are some values for which `prez_gop` is `2` – these are
months in which Ford became President following Nixon’s resignation. In
the new `president` variable created as part of our data cleaning, we
code these as `gop` (same as values when `prez_gop` is `1`).

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

We also clean the 538 `snp` data, which contains information related to
Standard & Poor’s stock market index.

``` r
snp = 
  read_csv("fivethirtyeight_datasets/snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 
```

Finally, we tidy the `unemployment` data so that it can be merged with
the `pols` and `snp` datasets.

``` r
unemployment = 
  read_csv("fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Now we merge the three datasets!

``` r
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

Notice that there are some `NA` values in the `close` and `unemployment`
variables, which indicate that the value of these variables is missing
at those locations.

Let’s talk about the 538 datasets. The `pols` data has 822 observations
and 11 variables and tells us about the party affiliation distribution
(democrat or republican) for governors and senators for a given year
from years 1947 to 2015. It also tells us whether the sitting president
was a democrat or republican. The `snp` data has 787 observations and 3
variables, ranging from years 0 to 99. The `unemployment` data has 816
observations and 3 variables ranging from years 1948 to 2015. In
Januarys in or after 1975 in which a democrat was president, the
**average unemployment rate was 6.57**. The average unemployment rate
over the same time period in which a republican was president was 6.47.

## Problem 2

Read and clean the Mr. Trash Wheel sheet:

- specify the sheet in the Excel file and to omit non-data entries (rows
  with notes / figures; columns containing notes) using arguments in
  read_excel
- use reasonable variable names
- omit rows that do not include dumpster-specific data
- Update the data to include a new homes_powered variable based on this
  calculation:

*Homes Powered - Each ton of trash equates to on average 500 kilowatts
of electricity. An average household will use 30 kilowatts per day.*

``` r
mr_trash_df= readxl::read_excel("202207 Trash Wheel Collection Data.xlsx", 
                                sheet = "Mr. Trash Wheel", 
                                range = "A2:N549") |> 
  janitor::clean_names() |> 
  mutate(
    year= as.numeric(year), 
    homes_powered = (weight_tons * 500)/30, 
    dumpster_name= "Mr. Trash Wheel"
    )
```

Use a similar process to import, clean, and organize the data for
Professor Trash Wheel and Gwynnda, and combine these with the Mr. Trash
Wheel dataset to produce a single tidy dataset.

``` r
prof_trash_df <- readxl::read_excel("202207 Trash Wheel Collection Data.xlsx", 
                                  sheet = "Professor Trash Wheel", 
                                  range = "A2:M96") |> 
  janitor::clean_names() |> 
  mutate(
    homes_powered = (weight_tons * 500)/30, 
    dumpster_name = "Prof. Trash Wheel"
  )

gwynnda_df <- readxl::read_excel("202207 Trash Wheel Collection Data.xlsx", 
                                 sheet = "Gwynnda Trash Wheel", 
                                 range = "A2:K108") |> 
  janitor::clean_names() |> 
  mutate(
    homes_powered = (weight_tons * 500) / 30, 
    dumpster_name = "Gwynnda Trash Wheel"  
  )

all_trash= bind_rows(mr_trash_df, prof_trash_df, gwynnda_df) |> 
  relocate(dumpster_name, dumpster, month, year, date)
```

*Upon inspecting full `all_trash` dataset, it was observed that one data
observation was miscoded. For Mr. Trash Wheel dumpster 383 (January
2020) the date shown in data is “1900-01-20”). Will replace the year of
this date with 2020 and I should follow-up to cross check trash
collection days for Mr. Trash Wheel to ensure the month and day have
been entered correctly.*

``` r
all_trash <- all_trash |> 
  mutate(date = if_else((dumpster == 383 & year == 2020),
                        paste0(as.Date("2020-01-20")), paste0(date))) 
```

*Write a paragraph about these data. Be sure to note the number of
observations in the resulting dataset, and give examples of key
variables.*

*The `all_trash` data set contains information about the types of trash
collected, total weight of trash in tons collected (`weight_tons`), and
an approximate value for number of homes powered by trash collection
(`homes_powered`) for the trash wheels: Mr. Trash Wheel, Prof. Trash
Wheel, Gwynnda Trash Wheel. The dataset contains trash collection data
for 2014-05-16 through 2022-07-29. There are 16 variables and 747
observations.*

*Note that plastic bag collection data are only reported for Gwynnda
Trash Wheel. Glass bottle, grocery bag, and chip bag collection data are
reported for Mr. Trash Wheel and Professor Trash Well. Sports ball
collection data are reported for Mr. Trash only.*

*For available data, what was the total weight of trash collected by
Professor Trash Wheel?*

*The total weight of trash collected by Professor Trash Wheel was 190.12
tons.*

*What was the total number of cigarette butts collected by Gwynnda in
July of 2021?*

*In July of 2021. Gwynnda collected In July of 2021, Gwynnda collected
16300 cigarette butts.*

## Problem 3

This problem uses data collected in an observational study to understand
the trajectory of Alzheimer’s disease (AD) biomarkers. Study
participants were free of Mild Cognitive Impairment (MCI), a stage
between the expected cognitive decline of normal aging and the more
serious decline of dementia, at the study baseline.

Basic demographic information were measured at the study baseline. The
study monitored the development of MCI and recorded the age of MCI onset
during the follow-up period, with the last visit marking the end of
follow-up. APOE4 is a variant of the apolipoprotein E gene,
significantly associated with a higher risk of developing Alzheimer’s
disease. The amyloid β 42/40 ratio holds significant promise for
diagnosing and predicting disease outcomes. This ratio undergoes changes
over time and has been linked to the manifestation of clinical symptoms
of Alzheimer’s disease.

Import, clean, and tidy the dataset of baseline demographics.

- Ensure that sex and APOE4 carrier status are appropriate encoded
  (i.e. not numeric),
- and remove any participants who do not meet the stated inclusion
  criteria (i.e. no MCI at baseline).

*Discuss important steps in the import process and relevant features of
the dataset.*

*The import and cleaning of the `baseline_df` dataset involves changing
all names to snake case using `clean_names()`, renaming the study
participant identifier and primary key to `study_id` for joining to the
`amyloid_df` dataset, replacing numerical indicators for `sex` to
interpretable character values where `1`= `male` and `0`= `female`, and
replacing numerical indicators for `apoe4` status so that `1`=
`apoe4 carrier` and `0`= `apoe4 non-carrier`. Finally, the dataset was
filtered to exclude participants who demonstrated MCI at baseline. One
participant (study_id: 234) was excluded.*

*The imported baseline data included 483 observations, the cleaned
baseline data has 482 observations.*

*How many participants were recruited, and of these how many develop
MCI?*

*The study recruited 482 eligible participants. Of these, 96
participants developed MCI during the study observation period.*

*What is the average baseline age? What proportion of women in the study
are APOE4 carriers?*

*The average age of participants at baseline is 65.04 years. The study
included 211 females, of which 29.86% were carriers for the APOE4 gene.*

Similarly, import, clean, and tidy the dataset of longitudinally
observed biomarker values; comment on the steps on the import process
and the features of the dataset.

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

*The import and cleaning of the `amyloid_df` dataset involves changing
all names to snake case using `clean_names()`. The imported amyloid data
included 487 observations, the cleaned baseline data has 487
observations with baseline, visit 2, visit 4, visit 6, and visit 8
measures of amyloid β 42/40 ratio.*

Check whether some participants appear in only the baseline or amyloid
datasets, and comment on your findings. Combine the demographic and
biomarker datasets so that only participants who appear in both datasets
are retained, and briefly describe the resulting dataset; export the
result as a CSV to your data directory.

return all rows from x without a match in y…
